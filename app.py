import asyncio
from pathlib import Path
from typing import Dict, List

import streamlit as st
import yaml
from loguru import logger as _logger
import shutil
import uuid

from metagpt.const import METAGPT_ROOT
from metagpt.ext.spo.components.optimizer import PromptOptimizer
from metagpt.ext.spo.utils.llm_client import SPO_LLM, RequestType


def get_user_workspace():
    if "user_id" not in st.session_state:
        st.session_state.user_id = str(uuid.uuid4())

    workspace_dir = Path("workspace") / st.session_state.user_id
    workspace_dir.mkdir(parents=True, exist_ok=True)
    return workspace_dir


def cleanup_workspace(workspace_dir: Path) -> None:
    try:
        if workspace_dir.exists():
            shutil.rmtree(workspace_dir)
            _logger.info(f"Cleaned up workspace directory: {workspace_dir}")
    except Exception as e:
        _logger.error(f"Error cleaning up workspace: {e}")


def get_all_templates() -> List[str]:
    """
    Get list of all available templates (both default and user-specific)
    :return: List of template names
    """
    settings_path = Path("metagpt/ext/spo/settings")

    # Get default templates
    templates = [f.stem for f in settings_path.glob("*.yaml")]

    # Get user-specific templates if user_id exists
    if "user_id" in st.session_state:
        user_path = settings_path / st.session_state.user_id
        if user_path.exists():
            user_templates = [
                f"{st.session_state.user_id}/{f.stem}" for f in user_path.glob("*.yaml")]
            templates.extend(user_templates)

    return sorted(list(set(templates)))


def load_yaml_template(template_path: Path) -> Dict:
    if template_path.exists():
        with open(template_path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    return {"prompt": "", "requirements": "", "count": None, "qa": [{"question": "", "answer": ""}]}


def save_yaml_template(template_path: Path, data: Dict) -> None:
    template_format = {
        "prompt": str(data.get("prompt", "")),
        "requirements": str(data.get("requirements", "")),
        "count": data.get("count"),
        "qa": [
            {"question": str(qa.get("question", "")).strip(
            ), "answer": str(qa.get("answer", "")).strip()}
            for qa in data.get("qa", [])
        ],
    }

    template_path.parent.mkdir(parents=True, exist_ok=True)

    with open(template_path, "w", encoding="utf-8") as f:
        yaml.dump(template_format, f, allow_unicode=True,
                  sort_keys=False, default_flow_style=False, indent=2)


def display_optimization_results(result_data):
    for result in result_data:
        round_num = result["round"]
        success = result["succeed"]
        prompt = result["prompt"]

        with st.expander(f"è½®æ¬¡ {round_num} {':white_check_mark:' if success else ':x:'}"):
            st.markdown("**æç¤ºè¯ï¼š**")
            st.code(prompt, language="text")
            st.markdown("<br>", unsafe_allow_html=True)

            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"**çŠ¶æ€ï¼š** {'æˆåŠŸ âœ… ' if success else 'å¤±è´¥ âŒ '}")
            with col2:
                st.markdown(f"**ä»¤ç‰Œæ•°ï¼š** {result['tokens']}")

            st.markdown("**å›ç­”ï¼š**")
            for idx, answer in enumerate(result["answers"]):
                st.markdown(f"**é—®é¢˜ {idx + 1}ï¼š**")
                st.text(answer["question"])
                st.markdown("**ç­”æ¡ˆï¼š**")
                st.text(answer["answer"])
                st.markdown("---")

    # æ€»ç»“
    success_count = sum(1 for r in result_data if r["succeed"])
    total_rounds = len(result_data)

    st.markdown("### æ€»ç»“")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("æ€»è½®æ¬¡", total_rounds)
    with col2:
        st.metric("æˆåŠŸè½®æ¬¡", success_count)


def main():
    if "optimization_results" not in st.session_state:
        st.session_state.optimization_results = []

    try:
        config_path = Path("config/config2.yaml")
        if config_path.exists():
            with open(config_path, "r", encoding="utf-8") as f:
                config_data = yaml.safe_load(f)
                if "llm" in config_data:
                    llm_config = config_data["llm"]
                    st.session_state.base_url = llm_config.get(
                        "base_url", "")
                    st.session_state.api_key = llm_config.get(
                        "api_key", "")
                    if "models" in config_data:
                        st.session_state.available_models = list(
                            config_data["models"].keys())
    except Exception as e:
        _logger.error(f"è¯»å–é…ç½®æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")

    workspace_dir = get_user_workspace()

    st.markdown(
        """
    <div style="background-color: #f0f2f6; padding: 20px; border-radius: 10px; margin-bottom: 25px">
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px">
            <h1 style="margin: 0;">SPO | è‡ªç›‘ç£æç¤ºè¯ä¼˜åŒ– ğŸ¤–</h1>
        </div>
        <div style="display: flex; gap: 20px; align-items: center">
            <a href="https://arxiv.org/pdf/2502.06855" target="_blank" style="text-decoration: none;">
                <img src="https://img.shields.io/badge/è®ºæ–‡-PDF-red.svg" alt="è®ºæ–‡">
            </a>
            <a href="https://github.com/Airmomo/SPO" target="_blank" style="text-decoration: none;">
                <img src="https://img.shields.io/badge/GitHub-ä»“åº“-blue.svg" alt="GitHub">
            </a>
            <span style="color: #666;">ä¸€ä¸ªè‡ªç›‘ç£æç¤ºè¯ä¼˜åŒ–æ¡†æ¶</span>
        </div>
    </div>
    """,
        unsafe_allow_html=True
    )

    # åˆ›å»ºå¯¼èˆªæ 
    tab_config, tab_template, tab_preview, tab_logs, tab_results, tab_test = st.tabs(
        ["LLM é…ç½®", "æ¨¡æ¿é…ç½®", "å½“å‰æ¨¡æ¿é¢„è§ˆ", "ä¼˜åŒ–æ—¥å¿—", "ä¼˜åŒ–ç»“æœ", "æµ‹è¯•ä¼˜åŒ–åæç¤ºè¯"])

    # é…ç½®é€‰é¡¹å¡
    with tab_config:
        st.header("LLM é…ç½®")

        # LLM è®¾ç½®
        st.subheader("LLM è®¾ç½®")

        base_url = st.text_input("BASE URL", value=st.session_state.get(
            "base_url", "https://api.example.com"))
        api_key = st.text_input(
            "API KEY", type="password", value=st.session_state.get("api_key", ""))
        model_name = st.text_input("æ¨¡å‹åç§°", value="")

        if st.button("è¿é€šæ€§æµ‹è¯•å¹¶æ·»åŠ æ¨¡å‹"):
            try:
                if not model_name:
                    st.error("è¯·è¾“å…¥æ¨¡å‹åç§°")
                    return

                # è¿›è¡ŒLLMè¿é€šæ€§æµ‹è¯•
                try:
                    from openai import OpenAI

                    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                    client = OpenAI(
                        api_key=api_key,
                        base_url=base_url
                    )

                    # æµ‹è¯•è¿é€šæ€§
                    response = client.chat.completions.create(
                        model=model_name,
                        messages=[{"role": "user", "content": "Hello"}],
                        temperature=0
                    )

                    # è¿é€šæ€§æµ‹è¯•æˆåŠŸï¼Œä¿å­˜é…ç½®
                    config_path = Path("config/config2.yaml")
                    config_data = {}
                    if config_path.exists():
                        with open(config_path, "r", encoding="utf-8") as f:
                            config_data = yaml.safe_load(f) or {}

                    config_data["llm"] = {
                        "api_type": "openai",
                        "base_url": base_url,
                        "api_key": api_key
                    }
                    if "models" not in config_data:
                        config_data["models"] = {}
                    config_data["models"][model_name] = {
                        "api_type": "openai",
                        "base_url": "${llm.base_url}",
                        "api_key": "${llm.api_key}",
                        "temperature": 0
                    }

                    with open(config_path, "w", encoding="utf-8") as f:
                        yaml.dump(config_data, f, allow_unicode=True,
                                  sort_keys=False, default_flow_style=False, indent=2)

                    st.session_state.base_url = base_url
                    st.session_state.api_key = api_key
                    st.session_state.available_models = list(
                        config_data["models"].keys())
                    st.session_state.config_loaded = True
                    st.success("è¿é€šæ€§æµ‹è¯•æˆåŠŸï¼Œé…ç½®å·²ä¿å­˜ï¼")
                except Exception as e:
                    st.error(f"LLMè¿é€šæ€§æµ‹è¯•å¤±è´¥ï¼š{str(e)}")
                    return
                finally:
                    if 'loop' in locals():
                        loop.close()

            except Exception as e:
                st.error(f"ä¿å­˜é…ç½®æ—¶å‡ºé”™ï¼š{str(e)}")

        # ä¼˜åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨è®¾ç½®
        st.subheader("æ¨¡å‹è®¾ç½®")
        opt_model = st.selectbox(
            "ä¼˜åŒ–æ¨¡å‹", st.session_state.get("available_models", ["Null"]), index=0
        )
        opt_temp = st.slider("ä¼˜åŒ–æ¸©åº¦", 0.0, 1.0, 0.7)

        eval_model = st.selectbox(
            "è¯„ä¼°æ¨¡å‹", st.session_state.get("available_models", ["Null"]), index=0
        )
        eval_temp = st.slider("è¯„ä¼°æ¸©åº¦", 0.0, 1.0, 0.3)

        exec_model = st.selectbox(
            "æ‰§è¡Œæ¨¡å‹", st.session_state.get("available_models", ["Null"]), index=0
        )
        exec_temp = st.slider("æ‰§è¡Œæ¸©åº¦", 0.0, 1.0, 0.0)

        # ä¼˜åŒ–å™¨è®¾ç½®
        st.subheader("ä¼˜åŒ–å™¨è®¾ç½®")
        initial_round = st.number_input("åˆå§‹è½®æ¬¡", 1, 100, 1)
        max_rounds = st.number_input("æœ€å¤§è½®æ¬¡", 1, 100, 10)

    # æ¨¡æ¿é…ç½®é€‰é¡¹å¡
    with tab_template:
        st.header("æ¨¡æ¿é…ç½®")

        # æ¨¡æ¿é€‰æ‹©/åˆ›å»º
        settings_path = Path("metagpt/ext/spo/settings")
        existing_templates = get_all_templates()
        template_options = existing_templates + ["åˆ›å»ºæ–°æ¨¡æ¿"]

        template_selection = st.selectbox("é€‰æ‹©æ¨¡æ¿", template_options)
        is_new_template = template_selection == "åˆ›å»ºæ–°æ¨¡æ¿"

        if is_new_template:
            template_name = st.text_input("æ–°æ¨¡æ¿åç§°")
        else:
            template_name = template_selection

        # åˆå§‹åŒ–template_path
        template_path = None
        if template_name:
            template_path = settings_path / f"{template_name}.yaml"
            template_data = load_yaml_template(template_path)

        # åŠ è½½æˆ–åˆå§‹åŒ–æ¨¡æ¿æ•°æ®
        template_data = {"prompt": "", "requirements": "", "qa": []}
        if template_path and template_path.exists():
            template_data = load_yaml_template(template_path)

        if "current_template" not in st.session_state or st.session_state.current_template != template_name:
            st.session_state.current_template = template_name
            st.session_state.qas = template_data.get("qa", [])
            st.session_state.prompt = template_data.get("prompt", "")
            st.session_state.requirements = template_data.get(
                "requirements", "")
        elif is_new_template and not template_name:
            # æ¸…ç©ºæ‰€æœ‰å†…å®¹
            st.session_state.current_template = template_name
            st.session_state.qas = []
            st.session_state.prompt = ""
            st.session_state.requirements = ""

        # ä½¿ç”¨session_stateä¸­çš„å€¼å¡«å……è¾“å…¥æ¡†
        prompt = st.text_area(
            "æç¤ºè¯", value=st.session_state.get("prompt", ""), height=100)
        requirements = st.text_area(
            "è¦æ±‚", value=st.session_state.get("requirements", ""), height=100)

        # é—®ç­”éƒ¨åˆ†
        st.subheader("é—®ç­”ç¤ºä¾‹")

        if "qas" not in st.session_state:
            st.session_state.qas = []

        # æ·»åŠ æ–°é—®ç­”æŒ‰é’®
        if st.button("æ·»åŠ æ–°é—®ç­”"):
            st.session_state.qas.append({"question": "", "answer": ""})

        # ç¼–è¾‘é—®ç­”
        new_qas = []
        for i in range(len(st.session_state.qas)):
            st.markdown(f"**é—®ç­” #{i + 1}**")
            col1, col2, col3 = st.columns([45, 45, 10])

            with col1:
                question = st.text_area(
                    f"é—®é¢˜ {i + 1}", st.session_state.qas[i].get("question", ""), key=f"q_{i}", height=100
                )
            with col2:
                answer = st.text_area(
                    f"ç­”æ¡ˆ {i + 1}", st.session_state.qas[i].get("answer", ""), key=f"a_{i}", height=100
                )
            with col3:
                if st.button("ğŸ—‘ï¸", key=f"delete_{i}"):
                    st.session_state.qas.pop(i)
                    st.rerun()

            new_qas.append({"question": question, "answer": answer})

        if template_name:
            template_path = settings_path / f"{template_name}.yaml"
            template_data = load_yaml_template(template_path)

            if not is_new_template:
                template_data = load_yaml_template(template_path)
                if "current_template" not in st.session_state or st.session_state.current_template != template_name:
                    st.session_state.current_template = template_name
                    st.session_state.qas = template_data.get("qa", [])
                    prompt = template_data.get("prompt", "")
                    requirements = template_data.get("requirements", "")
                else:
                    # æ¸…ç©ºå†…å®¹
                    st.session_state.qas = []
                    prompt = ""
                    requirements = ""
                    
            if st.button("ä¿å­˜æ¨¡æ¿"):
                if not template_name:
                    st.error("å¿…é¡»å¡«å†™æ¨¡æ¿åç§°ï¼")
                else:
                    new_template_data = {
                        "prompt": prompt, "requirements": requirements, "count": None, "qa": new_qas}

                    save_yaml_template(template_path, new_template_data)

                    st.session_state.qas = new_qas
                    st.success(f"æ¨¡æ¿å·²ä¿å­˜åˆ° {template_path}")

    # å½“å‰æ¨¡æ¿é¢„è§ˆé€‰é¡¹å¡
    with tab_preview:
        if "current_template" in st.session_state:
            st.header("å½“å‰æ¨¡æ¿é¢„è§ˆ")
            preview_data = {"qa": new_qas if 'new_qas' in locals() else [],
                            "requirements": requirements if 'requirements' in locals() else "",
                            "prompt": prompt if 'prompt' in locals() else ""}
            st.code(yaml.dump(preview_data, allow_unicode=True), language="yaml")

    # ä¼˜åŒ–æ—¥å¿—é€‰é¡¹å¡
    with tab_logs:
        st.header("ä¼˜åŒ–æ—¥å¿—")
        log_container = st.empty()

        class StreamlitSink:
            def write(self, message):
                current_logs = st.session_state.get("logs", [])
                current_logs.append(message.strip())
                st.session_state.logs = current_logs
                log_container.code(
                    "\n".join(current_logs), language="plaintext")

        streamlit_sink = StreamlitSink()
        _logger.remove()

        def prompt_optimizer_filter(record):
            return "optimizer" in record["name"].lower()

        _logger.add(
            streamlit_sink.write,
            format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
            filter=prompt_optimizer_filter,
        )
        _logger.add(METAGPT_ROOT /
                    "logs/{time:YYYYMMDD}.txt", level="DEBUG")

        # å¼€å§‹ä¼˜åŒ–æŒ‰é’®
        if st.button("å¼€å§‹ä¼˜åŒ–"):
            try:
                # Initialize LLM
                SPO_LLM.initialize(
                    optimize_kwargs={"model": opt_model, "temperature": opt_temp, "base_url": base_url,
                                     "api_key": api_key},
                    evaluate_kwargs={"model": eval_model, "temperature": eval_temp, "base_url": base_url,
                                     "api_key": api_key},
                    execute_kwargs={"model": exec_model, "temperature": exec_temp, "base_url": base_url,
                                    "api_key": api_key},
                )

                # Create optimizer instance
                optimizer = PromptOptimizer(
                    optimized_path=str(workspace_dir),
                    initial_round=initial_round,
                    max_rounds=max_rounds,
                    template=f"{template_name}.yaml",
                    name=template_name,
                )

                # Run optimization with progress bar
                with st.spinner("æ­£åœ¨ä¼˜åŒ–æç¤ºè¯..."):
                    optimizer.optimize()

                st.success("ä¼˜åŒ–å®Œæˆï¼")
                prompt_path = optimizer.root_path / "prompts"
                result_data = optimizer.data_utils.load_results(
                    prompt_path)
                print(result_data)
                st.session_state.optimization_results = result_data

            except Exception as e:
                st.error(f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
                _logger.error(f"ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºé”™ï¼š{str(e)}")

    # ä¼˜åŒ–ç»“æœé€‰é¡¹å¡
    with tab_results:
        st.header("ä¼˜åŒ–ç»“æœ")
        if st.session_state.optimization_results:
            display_optimization_results(
                st.session_state.optimization_results)

    # æµ‹è¯•ä¼˜åŒ–åæç¤ºè¯é€‰é¡¹å¡
    with tab_test:
        st.header("æµ‹è¯•ä¼˜åŒ–åçš„æç¤ºè¯")
        col1, col2 = st.columns(2)

        with col1:
            test_prompt = st.text_area(
                "ä¼˜åŒ–åçš„æç¤ºè¯", value="", height=200, key="test_prompt")

        with col2:
            test_question = st.text_area(
                "ä½ çš„é—®é¢˜", value="", height=200, key="test_question")

        if st.button("æµ‹è¯•æç¤ºè¯"):
            if test_prompt and test_question:
                try:
                    with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                        SPO_LLM.initialize(
                            optimize_kwargs={"model": opt_model, "temperature": opt_temp, "base_url": base_url,
                                             "api_key": api_key},
                            evaluate_kwargs={"model": eval_model, "temperature": eval_temp, "base_url": base_url,
                                             "api_key": api_key},
                            execute_kwargs={"model": exec_model, "temperature": exec_temp, "base_url": base_url,
                                            "api_key": api_key},
                        )

                        llm = SPO_LLM.get_instance()
                        messages = [
                            {"role": "user", "content": f"{test_prompt}\n\n{test_question}"}]

                        async def get_response():
                            return await llm.responser(request_type=RequestType.EXECUTE, messages=messages)

                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            response = loop.run_until_complete(
                                get_response())
                        finally:
                            loop.close()

                        st.subheader("å›ç­”ï¼š")
                        st.markdown(response)

                except Exception as e:
                    st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™ï¼š{str(e)}")
                else:
                    st.warning("è¯·è¾“å…¥æç¤ºè¯å’Œé—®é¢˜ã€‚")


if __name__ == "__main__":
    main()
